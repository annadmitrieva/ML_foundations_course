{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ДПО МЛ 4-6 - упражнения"
      ],
      "metadata": {
        "id": "1c0ViazNy3ds"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задача 1: кластеризация запросов и снижение размерности данных"
      ],
      "metadata": {
        "id": "RH055wuuPmwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Данные:** датасет amazon_queries.csv\n",
        "\n",
        "**Основное задание:**\n",
        "\n",
        "1.   Выполните предобработку датасета. Подумайте, нужно ли делить данные на тренировочные и тестовые;\n",
        "2.   Выполните кластеризациюю методом К средних (не применяйте другие методы на этом шаге, если только у вас нет мощного компьютера);\n",
        "3.   Посмотрите на запросы каждого кластера;\n",
        "4.   Снизьте размерность данных при помощи любого известного вам метода (подумайте, какой метод здесь будет наиболее подходящим);\n",
        "5.   Кластеризуйте данные сниженной размерности такой же моделью, как и в шаге 2 (подумайте, что значит \"такая же модель\");\n",
        "6.   При помощи метрик, не требующих наличия тестового множества, сравните качество кластеризации на исходных данных и данных сниженной размерности.\n",
        "\n",
        "**Дополнительно** можете найти оптимальное число кластеров методом локтя (осторожно, вычисления могут занять время).\n",
        "\n"
      ],
      "metadata": {
        "id": "cj9rfRx4icSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задача 2: тематическое моделирование методом LDA"
      ],
      "metadata": {
        "id": "SSBXHtTDmw4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Данные:** АРХИВ лемматизированных русских текстов ruslit_lemmas.zip\n",
        "\n",
        "**Основное задание:**\n",
        "\n",
        "1.   Достаньте тексты и (на всякий случай) их названия из архива так, как показано в коде;\n",
        "2.   Векторизуйте тексты. Ограничьте количество используемых признаков до 6000 и используйте стоп-слова;\n",
        "3.   Сделайте тематическое моделирование при помощи латентного размещения Дирихле. Число компонент выберите любое;\n",
        "4.   Выведите топовые слова каждой компоненты.\n",
        "\n"
      ],
      "metadata": {
        "id": "uHGpm-8qxNpS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Извлечение информации из архивов:"
      ],
      "metadata": {
        "id": "4KDCA0MMwaAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "path_to_archive = '/content/drive/MyDrive/ML_training_data/ruslit_lemmas.zip'\n",
        "\n",
        "def texts_from_zip(path_to_archive):\n",
        "    texts = []\n",
        "    with ZipFile(path_to_archive) as zip_archive:\n",
        "        for name in zip_archive.namelist():\n",
        "            if '.txt' in name:\n",
        "                text = zip_archive.read(name)\n",
        "                text = text.decode('utf-8')\n",
        "                texts.append(text)\n",
        "    return texts\n",
        "\n",
        "def get_filenames(path_to_archive):\n",
        "\n",
        "    names = []\n",
        "\n",
        "    with ZipFile(path_to_archive) as zip_archive:\n",
        "        for name in zip_archive.namelist():\n",
        "            if '.txt' in name:\n",
        "                names.append(name.split('/')[1])\n",
        "\n",
        "    return names"
      ],
      "metadata": {
        "id": "YMK3211iwX5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задача 3: ансамблевое обучение"
      ],
      "metadata": {
        "id": "vYTWjbsZPqyh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Датасет:** данные о качестве воды BKB_WaterQualityData_2020084.csv.\n",
        "\n",
        "**Основное задание:**\n",
        "\n",
        "\n",
        "1.   Выполните предобработку датасета. Ваша зависимая переменная - Site_Id. Ваши независимые переменные: Salinity (ppt), Dissolved Oxygen (mg/L), pH (standard units), Secchi Depth (m), Water Depth (m), Water Temp (?C), AirTemp (C). Подумайте, надо ли что-то кодировать и/или разделять выборку на тренировочное и тестовое множество.\n",
        "2.   Используйте модели ансамблевого обучения (как минимум, рандомный лес и градиентный бустинг), чтобы по данным о качестве воды предсказать место, откуда был взят образец. Оцените качество предсказаний.\n",
        "\n",
        "\n",
        "**Дополнительно:** примените GridSearchCV для подбора оптимальных параметров рандомного леса.\n",
        "\n",
        "**В этом задании можно попробовать:** другие методы ансамблирования, например, обычный бустинг и стекинг.\n"
      ],
      "metadata": {
        "id": "ilxHDU5Wo4DF"
      }
    }
  ]
}