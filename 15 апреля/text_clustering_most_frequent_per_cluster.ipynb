{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Кластеризация и выявление самых частотных слов в каждом кластере"
      ],
      "metadata": {
        "id": "bQmy0tqu6aCJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задача:** кластеризовать тексты новостей и посмотреть, какие слова являются самыми частотными для каждого кластера.\n",
        "\n",
        "**Датасет:** 20newsgroups, встроенный датасет из sklearn: https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset\n",
        "\n",
        "\n",
        "**Используемые технологии:** KMeans для кластеризации, регулярки для токенизации, список стоп-слов из NLTK, некоторые типы данных из collections."
      ],
      "metadata": {
        "id": "fQ8cpTMT6grM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка данных\n",
        "\n",
        "20newsgroups загружается прямо из sklearn, поэтому его загрузка выглядит не так, как загрузка обычного датасета из файла."
      ],
      "metadata": {
        "id": "1tz821H67S8q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbFYziDRuxv1"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "v6BwC5AMvMSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "3L2SxDwK2qOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score"
      ],
      "metadata": {
        "id": "k0DOPX7v3g2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bunch - специальный тип данных, применяемый в sklearn.datasets. Вне sklearn мы им пользоваться не будем\n",
        "type(fetch_20newsgroups())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "6shti9ie1GHh",
        "outputId": "45f768be-151e-473b-a0d4-1657d0ae4c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils._bunch.Bunch"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>sklearn.utils._bunch.Bunch</b><br/>def __init__(**kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/sklearn/utils/_bunch.py</a>Container object exposing keys as attributes.\n",
              "\n",
              "Bunch objects are sometimes used as an output for functions and methods.\n",
              "They extend dictionaries by enabling values to be accessed by key,\n",
              "`bunch[&quot;value_key&quot;]`, or by an attribute, `bunch.value_key`.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; from sklearn.utils import Bunch\n",
              "&gt;&gt;&gt; b = Bunch(a=1, b=2)\n",
              "&gt;&gt;&gt; b[&#x27;b&#x27;]\n",
              "2\n",
              "&gt;&gt;&gt; b.b\n",
              "2\n",
              "&gt;&gt;&gt; b.a = 3\n",
              "&gt;&gt;&gt; b[&#x27;a&#x27;]\n",
              "3\n",
              "&gt;&gt;&gt; b.c = 6\n",
              "&gt;&gt;&gt; b[&#x27;c&#x27;]\n",
              "6</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 1);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bunch устроен как словарь: по ключам можно достать тексты, имена файлов, названия новостных групп, их номера и описания\n",
        "# target - числовые значения топиков, удобные для подачи в модель, а target_names - их полные имена\n",
        "fetch_20newsgroups().keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6a-qFQJ1OR8",
        "outputId": "351b4be2-a9ef-49c6-fab2-318793a1f1aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Мы будем кластеризовать тексты. Исходные номера новостных групп сохраним в y на всякий случай, но пользоваться ими не будем.\n",
        "# Вы можете попробовать разделить тексты на 20 кластеров (это число топиков в датасете) и сравнить ваши кластеры с y\n",
        "X = fetch_20newsgroups()['data']\n",
        "y = fetch_20newsgroups()['target']"
      ],
      "metadata": {
        "id": "9m9BC-kV1dPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "Vh-MDf1k1wDo",
        "outputId": "ae6d075a-c158-4b15-ddd8-cc16f8bb5018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo1wv2sS1-op",
        "outputId": "93b8bc08-7c06-4908-885d-cc8ddfea0745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вот такие темы новостей есть в датасете:"
      ],
      "metadata": {
        "id": "xyNE8-b98nZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(enumerate(fetch_20newsgroups()['target_names']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbqmp-AH2ALZ",
        "outputId": "3a968b2c-c6e9-47e9-8b00-31c1ef3458f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 'alt.atheism'),\n",
              " (1, 'comp.graphics'),\n",
              " (2, 'comp.os.ms-windows.misc'),\n",
              " (3, 'comp.sys.ibm.pc.hardware'),\n",
              " (4, 'comp.sys.mac.hardware'),\n",
              " (5, 'comp.windows.x'),\n",
              " (6, 'misc.forsale'),\n",
              " (7, 'rec.autos'),\n",
              " (8, 'rec.motorcycles'),\n",
              " (9, 'rec.sport.baseball'),\n",
              " (10, 'rec.sport.hockey'),\n",
              " (11, 'sci.crypt'),\n",
              " (12, 'sci.electronics'),\n",
              " (13, 'sci.med'),\n",
              " (14, 'sci.space'),\n",
              " (15, 'soc.religion.christian'),\n",
              " (16, 'talk.politics.guns'),\n",
              " (17, 'talk.politics.mideast'),\n",
              " (18, 'talk.politics.misc'),\n",
              " (19, 'talk.religion.misc')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как видите, если брать только первую часть названия темы (до точки), можно выделить 7 топиков. Давайте попробуем поделить нашу выборку на 7 кластеров."
      ],
      "metadata": {
        "id": "ldL7P8Pc8uxl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Кластеризация"
      ],
      "metadata": {
        "id": "iIU8Xdk0851y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_CLUSTERS = 7"
      ],
      "metadata": {
        "id": "WU1AH-Py2EQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# векторизуем тексты, чтобы привести их в машиночитаемый формат\n",
        "vectorizer = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "bFtnaC8M3EIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = vectorizer.fit_transform(X)"
      ],
      "metadata": {
        "id": "7zj3xiNl3GTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_means_clusters = KMeans(n_clusters=N_CLUSTERS).fit(vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEHtoDJz3YK4",
        "outputId": "fb20b119-a79e-423f-f5e9-343010e1edec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_means_clusters.labels_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWybgEhN4QPT",
        "outputId": "36555490-3be7-4c8b-e209-efaee660e6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 4, 1, ..., 1, 4, 4], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем оценить нашу кластеризацию при помощи коэффициента силуэта. Очевидно, что кластеры новостей разделены плохо: судя по отрицательному значению коэффициента силуэта, темы \"наползают\" друг на друга. Это в целом ожидаемо: очевидно, что слова из темы \"атеизм\" могут пересекаться со словами из темы \"религия\" и т.п., \"смешивая\" эти топики."
      ],
      "metadata": {
        "id": "B6nU5vfS9G80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_score(vectors, k_means_clusters.labels_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBZWvhaEFXf0",
        "outputId": "0b3eab2b-7b91-4789-c9ea-b49f58f1d5c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.006532008572238636"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Самые частотные слова"
      ],
      "metadata": {
        "id": "diVv-9kx9kHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Алгоритм:\n",
        "\n",
        "\n",
        "*   Делаем словарь, где номеру кластера будет соответствовать список всех принадлежащих ему текстов (воспользуемся defaultdict(list));\n",
        "*   Для каждого кластера создаем Counter токенов и вносим в него сведеня о количестве токенов во всех текстах;\n",
        "*   Выводим список частотных слов для каждого кластера.\n",
        "\n"
      ],
      "metadata": {
        "id": "i2L0rzH59q5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter"
      ],
      "metadata": {
        "id": "W2tHXB5u8Zy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "w836coAl_Q-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "NwBNdE6oCLCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем пустой словарь texts_per_cluster, где ключам будут соответствовать списки. Затем мы будем итерироваться по всем лейблам кластеров, которые присвоила текстам модель KMeans. k_means_clusters.labels_ - это список чисел, каждое из которых обозначает, какому кластеру принадлежит соответствующий текст из матрицы X (k_means_clusters.labels_[0] вернет номер кластера для X[0] - первого текста в выборке, k_means_clusters.labels_[i] вернет номер кластера для X[i]).\n",
        "\n",
        "На каждом шаге цикла ниже мы получаем порядковый номер объекта, который мы рассматриваем в данный момент (i) и номер кластера, в который этот объект входит (label). Мы достаем из множества X текст, соответствующий порядковому номеру i: X[i]. Этот текст нам нужно добавить в список текстов, принадлежащих данному кластеру. Поэтому мы обращаемся к словарю texts_per_cluster по ключу label и добавляем туда текст X[i]."
      ],
      "metadata": {
        "id": "fY0YRclq-1HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts_per_cluster = defaultdict(list)\n",
        "\n",
        "for i, label in enumerate(k_means_clusters.labels_):\n",
        "  texts_per_cluster[label].append(X[i])"
      ],
      "metadata": {
        "id": "OFig-Dsh8il1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# видно, что ключи в словаре соответствуют номерам кластеров\n",
        "texts_per_cluster.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFMj48py-P-I",
        "outputId": "10254f10-4f55-46f2-80f8-f8ecad94cb75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([1, 4, 5, 3, 0, 6, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# попробуйте достать первые десять текстов первого кластера"
      ],
      "metadata": {
        "id": "FibfOM4bBUyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "texts_per_cluster[0][:10]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vpanCoKaBbPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итак, для каждого кластера у нас теперь есть списки текстов, которые в него входят. Теперь нам нужно сделать частотный словарь для каждого кластера.\n",
        "\n",
        "Сделаем функцию, которая принимает на вход все тексты кластера. Функция будет исполнять следующие действия:\n",
        "\n",
        "1.   Создание пустого объекта Counter (это тип данных, который принимает на вход список элементов и возвращает словарь, где каждому уникальному элементу соответствует количество раз, сколько этот элемент встретился в списке). Это будет частотный список для всего списка текстов.\n",
        "2.   Далее работаем с каждым текстом. Каждый текст токенизируется и очищается от стоп-слов. Затем мы создаем объект Counter для токенов этого текста, тем самым создавая частотный словарь одного текста. Эти частоты нам нужно записать в общий Counter. Поскольку Counter - это словарь, мы можем работать с ним так же, как с другими словарями в питоне. Поэтому мы воспользуемся методом update(), который будет обновлять наш частотный список для всего списка текстов, пополняя его новыми значениями из каждого конкретного текста.\n",
        "3.   Вернём частотный список для всего списка текстов.     \n",
        "\n"
      ],
      "metadata": {
        "id": "txIKNnAjBiIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_most_frequent_words(list_of_texts):\n",
        "  c = Counter()\n",
        "\n",
        "  for text in list_of_texts:\n",
        "    tokens = re.findall('\\w+', text.lower())\n",
        "    clean_tokens = [token for token in tokens if token not in stopwords.words(\"english\")]\n",
        "    current_c = Counter(clean_tokens)\n",
        "    c.update(current_c)\n",
        "\n",
        "  return c"
      ],
      "metadata": {
        "id": "qUwAWOZi-Squ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нам нужно будет сортировать значения в частотном словаре от большого к малому, поэтому мы немного изменим функцию, которую написали на практике в разделе со звёздочкой. Изменение заключается в добавлении аргумента reverse=True. По умолчанию значения в отсортированном списке идут от меньшего к большему, но этот аргумент изменяет порядок значений."
      ],
      "metadata": {
        "id": "nTnTEdaRDOj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_dict_descending(d):\n",
        "  # сортируем словарь по возрастанию\n",
        "  return {k: v for k, v in sorted(d.items(), key=lambda item: item[1], reverse=True)}"
      ],
      "metadata": {
        "id": "9BwYOzpQAN2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итак, осталось для каждого кластера получить самые частотные слова, отсортировать их и записать в словарь таким образом, чтобы по ключу (номеру кластера) можно было достать отсортированный частотный список слов этого кластера.\n",
        "\n",
        "Мы снова создадим объект defaultdict(list), чтобы хранить там пары из ключей  - номеров кластеров - и значений: отсортированных частотных списков слов этого кластера. Затем для каждого номера кластера при помощи созданной нами функции get_most_frequent_words получим список слов и их частот. Полученные частотные списки отсортируем и запишем в словарь most_frequent_words_counters по ключу, соответствующему номеру кластера."
      ],
      "metadata": {
        "id": "AqgLDMzsDgOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "most_frequent_words_counters = defaultdict(list)\n",
        "\n",
        "for i in range(N_CLUSTERS):\n",
        "  print(i)\n",
        "  word_counts = get_most_frequent_words(texts_per_cluster[i])\n",
        "  most_frequent_words_counters[i] = list(sort_dict_descending(word_counts).keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_CSClVW_kKP",
        "outputId": "9700180f-8377-4a4f-8316-80dedf994fa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "CPU times: user 6min 17s, sys: 54.3 s, total: 7min 11s\n",
            "Wall time: 7min 42s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на 20 самых частотных слов каждого кластера. Как видно, они довольно шумные, а также сильно пересекаются. Возможно, дальнейшая предобработка текстов могла бы улучшить качество кластеризации."
      ],
      "metadata": {
        "id": "QhIb0gXcE1hK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in most_frequent_words_counters.items():\n",
        "  print(k, v[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBC4ek4rBDQ7",
        "outputId": "2f0b7fcf-0301-4192-a397-dc2b377a5815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 ['edu', 'team', '2', '1', 'subject', 'game', 'lines', 'organization', 'year', 'writes', 'ca', 'would', '3', 'one', 'article', '0', 'season', 'hockey', '4', 'good']\n",
            "1 ['edu', 'com', 'lines', 'subject', 'organization', 'x', 'writes', 'article', '1', 'one', 'would', 'like', '2', 'get', 'university', 'posting', 'host', 'use', 'know', 'nntp']\n",
            "2 ['edu', 'pitt', 'gordon', 'banks', 'geb', 'cs', 'article', 'writes', 'subject', 'organization', 'lines', 'n3jxp', 'skepticism', 'chastity', 'intellect', 'cadre', 'dsl', 'shameful', 'surrender', 'soon']\n",
            "3 ['com', 'edu', 'writes', 'keith', 'sandvik', 'subject', 'lines', 'article', 'organization', 'morality', 'sgi', 'objective', 'livesey', 'caltech', 'people', 'would', 'one', 'kent', 'apple', 'jon']\n",
            "4 ['ax', '1', '0', 'edu', '3', '2', 'q', 'w', 'subject', 'lines', 'max', 'r', 'organization', '7', 'p', 'com', 'g', '4', '5', '_']\n",
            "5 ['one', 'would', 'people', 'edu', 'x', 'god', '1', 'think', 'like', 'subject', 'com', 'know', 'also', 'time', 'us', 'get', 'lines', 'may', '2', 'even']\n",
            "6 ['edu', 'cmu', 'andrew', 'subject', 'organization', 'lines', 'carnegie', 'mellon', 'pittsburgh', 'host', 'posting', 'nntp', 'pa', 'com', 'reply', 'writes', 'computer', 'cs', 'know', 'article']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XP08nGiDBcar"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}